{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c1e22a",
   "metadata": {},
   "source": [
    "# ðŸ“Š Ensemble Learning: Bagging vs Boosting vs Stacking (Telco Churn Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15827c",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates three major ensemble techniques:\n",
    "- **Bagging** (Random Forest)\n",
    "- **Boosting** (XGBoost)\n",
    "- **Stacking** (with multiple base learners)\n",
    "\n",
    "We will use the Telco Customer Churn dataset, perform preprocessing, train all models, and compare their results with ROC curves, confusion matrices, and bar plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca5e03",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore the Telco Churn Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset (make sure the CSV is in your environment)\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4833d835",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc426f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop customerID and handle missing values\n",
    "df = df.drop(columns='customerID')\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode target\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "X = pd.get_dummies(df.drop('Churn', axis=1), drop_first=True)\n",
    "y = df['Churn']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb2acd",
   "metadata": {},
   "source": [
    "## Step 3: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e23380",
   "metadata": {},
   "source": [
    "## Step 4: Bagging - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c8e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07bf2d",
   "metadata": {},
   "source": [
    "## Step 5: Boosting - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ae0cc",
   "metadata": {},
   "source": [
    "## Step 6: Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b41f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('svc', SVC(probability=True))\n",
    "]\n",
    "\n",
    "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stack.fit(X_train, y_train)\n",
    "y_pred_stack = stack.predict(X_test)\n",
    "\n",
    "print(\"Stacking Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_stack))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d66e9",
   "metadata": {},
   "source": [
    "## Step 7: ROC Curves and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict probabilities\n",
    "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
    "xgb_probs = xgb.predict_proba(X_test)[:, 1]\n",
    "stack_probs = stack.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curves\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_probs)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, xgb_probs)\n",
    "fpr_stack, tpr_stack, _ = roc_curve(y_test, stack_probs)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest (AUC = {:.2f})'.format(auc(fpr_rf, tpr_rf)))\n",
    "plt.plot(fpr_xgb, tpr_xgb, label='XGBoost (AUC = {:.2f})'.format(auc(fpr_xgb, tpr_xgb)))\n",
    "plt.plot(fpr_stack, tpr_stack, label='Stacking (AUC = {:.2f})'.format(auc(fpr_stack, tpr_stack)))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for All Ensemble Methods')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrices\n",
    "models = [('Random Forest', y_pred_rf), ('XGBoost', y_pred_xgb), ('Stacking', y_pred_stack)]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "for i, (name, preds) in enumerate(models):\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot(ax=axes[i])\n",
    "    axes[i].set_title(f'{name} Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2512971b",
   "metadata": {},
   "source": [
    "## Step 8: Bar Plot of F1-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_scores = {\n",
    "    'Random Forest': f1_score(y_test, y_pred_rf),\n",
    "    'XGBoost': f1_score(y_test, y_pred_xgb),\n",
    "    'Stacking': f1_score(y_test, y_pred_stack)\n",
    "}\n",
    "\n",
    "# Bar plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(f1_scores.keys(), f1_scores.values(), color='skyblue')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Comparison Across Ensemble Methods')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
